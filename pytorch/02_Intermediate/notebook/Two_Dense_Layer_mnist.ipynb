{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import utils\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Train Data Done ! \n",
      "Downloading Test Data Done ! \n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = datasets.MNIST(root='../data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "print(\"Downloading Train Data Done ! \")\n",
    "\n",
    "mnist_test = datasets.MNIST(root='../data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "print(\"Downloading Test Data Done ! \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear1 = nn.Linear(784, 256)\n",
    "        self.linear2 = nn.Linear(256, 10)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = F.relu((self.linear1(X)))\n",
    "        X = self.linear2(X)\n",
    "        return X\n",
    "\n",
    "model = Model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration maker Done !\n",
      "Epoch :  1 Iteration :  100  Loss :  0.7335117340087891\n",
      "Epoch :  1 Iteration :  200  Loss :  0.5353356552124023\n",
      "Epoch :  1 Iteration :  300  Loss :  0.4490953063964844\n",
      "Epoch :  1 Iteration :  400  Loss :  0.3968754959106445\n",
      "Epoch :  1 Iteration :  500  Loss :  0.3602557067871094\n",
      "Epoch :  1 Iteration :  600  Loss :  0.3354418182373047\n",
      "Epoch :  1  Loss :  0.3354418182373047\n",
      "Epoch :  2 Iteration :  100  Loss :  0.1705564498901367\n",
      "Epoch :  2 Iteration :  200  Loss :  0.15946409225463867\n",
      "Epoch :  2 Iteration :  300  Loss :  0.15276912689208985\n",
      "Epoch :  2 Iteration :  400  Loss :  0.15057459831237793\n",
      "Epoch :  2 Iteration :  500  Loss :  0.14503700256347657\n",
      "Epoch :  2 Iteration :  600  Loss :  0.14219139099121095\n",
      "Epoch :  2  Loss :  0.14219139099121095\n",
      "Epoch :  3 Iteration :  100  Loss :  0.10364503860473633\n",
      "Epoch :  3 Iteration :  200  Loss :  0.09850584030151367\n",
      "Epoch :  3 Iteration :  300  Loss :  0.09970076243082682\n",
      "Epoch :  3 Iteration :  400  Loss :  0.09775398254394531\n",
      "Epoch :  3 Iteration :  500  Loss :  0.09803734588623046\n",
      "Epoch :  3 Iteration :  600  Loss :  0.09742892583211263\n",
      "Epoch :  3  Loss :  0.09742892583211263\n",
      "Epoch :  4 Iteration :  100  Loss :  0.0656384563446045\n",
      "Epoch :  4 Iteration :  200  Loss :  0.06768746376037597\n",
      "Epoch :  4 Iteration :  300  Loss :  0.06881801605224609\n",
      "Epoch :  4 Iteration :  400  Loss :  0.07202191352844238\n",
      "Epoch :  4 Iteration :  500  Loss :  0.07150882720947266\n",
      "Epoch :  4 Iteration :  600  Loss :  0.07084365208943685\n",
      "Epoch :  4  Loss :  0.07084365208943685\n",
      "Epoch :  5 Iteration :  100  Loss :  0.054083609580993654\n",
      "Epoch :  5 Iteration :  200  Loss :  0.052395687103271485\n",
      "Epoch :  5 Iteration :  300  Loss :  0.05376594543457031\n",
      "Epoch :  5 Iteration :  400  Loss :  0.053677544593811036\n",
      "Epoch :  5 Iteration :  500  Loss :  0.05379545593261719\n",
      "Epoch :  5 Iteration :  600  Loss :  0.053847185770670575\n",
      "Epoch :  5  Loss :  0.053847185770670575\n",
      "Epoch :  6 Iteration :  100  Loss :  0.04283069133758545\n",
      "Epoch :  6 Iteration :  200  Loss :  0.04305961132049561\n",
      "Epoch :  6 Iteration :  300  Loss :  0.043155555725097654\n",
      "Epoch :  6 Iteration :  400  Loss :  0.04273928642272949\n",
      "Epoch :  6 Iteration :  500  Loss :  0.042591724395751956\n",
      "Epoch :  6 Iteration :  600  Loss :  0.042555901209513344\n",
      "Epoch :  6  Loss :  0.042555901209513344\n",
      "Epoch :  7 Iteration :  100  Loss :  0.03244595766067505\n",
      "Epoch :  7 Iteration :  200  Loss :  0.03408633232116699\n",
      "Epoch :  7 Iteration :  300  Loss :  0.0338128916422526\n",
      "Epoch :  7 Iteration :  400  Loss :  0.033720703125\n",
      "Epoch :  7 Iteration :  500  Loss :  0.033916282653808597\n",
      "Epoch :  7 Iteration :  600  Loss :  0.03390238761901856\n",
      "Epoch :  7  Loss :  0.03390238761901856\n",
      "Epoch :  8 Iteration :  100  Loss :  0.02346569538116455\n",
      "Epoch :  8 Iteration :  200  Loss :  0.023072972297668456\n",
      "Epoch :  8 Iteration :  300  Loss :  0.0240980323155721\n",
      "Epoch :  8 Iteration :  400  Loss :  0.02467975616455078\n",
      "Epoch :  8 Iteration :  500  Loss :  0.025870725631713866\n",
      "Epoch :  8 Iteration :  600  Loss :  0.025986998875935873\n",
      "Epoch :  8  Loss :  0.025986998875935873\n",
      "Epoch :  9 Iteration :  100  Loss :  0.020221431255340577\n",
      "Epoch :  9 Iteration :  200  Loss :  0.01984480142593384\n",
      "Epoch :  9 Iteration :  300  Loss :  0.019234485626220703\n",
      "Epoch :  9 Iteration :  400  Loss :  0.01943344473838806\n",
      "Epoch :  9 Iteration :  500  Loss :  0.019967206954956053\n",
      "Epoch :  9 Iteration :  600  Loss :  0.020930999120076496\n",
      "Epoch :  9  Loss :  0.020930999120076496\n",
      "Epoch :  10 Iteration :  100  Loss :  0.016565544605255125\n",
      "Epoch :  10 Iteration :  200  Loss :  0.015263166427612305\n",
      "Epoch :  10 Iteration :  300  Loss :  0.01614484151204427\n",
      "Epoch :  10 Iteration :  400  Loss :  0.0161797297000885\n",
      "Epoch :  10 Iteration :  500  Loss :  0.01628180694580078\n",
      "Epoch :  10 Iteration :  600  Loss :  0.0167751677831014\n",
      "Epoch :  10  Loss :  0.0167751677831014\n",
      "Training Done !\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "data_iter = torch.utils.data.DataLoader(mnist_train, batch_size=100, shuffle=True, num_workers=1)\n",
    "\n",
    "print(\"Iteration maker Done !\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    avg_loss = 0\n",
    "    total_batch = len(mnist_train) // batch_size\n",
    "    for i, (batch_img, batch_lab) in enumerate(data_iter):\n",
    "        X = Variable(batch_img.view(-1, 28*28))\n",
    "        Y = Variable(batch_lab)\n",
    "        \n",
    "        y_pred = model.forward(X)\n",
    "        \n",
    "        loss = criterion(y_pred, Y)\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss\n",
    "        if (i+1)%100 == 0 :\n",
    "            print(\"Epoch : \", epoch+1, \"Iteration : \", i+1, \" Loss : \", avg_loss.data.numpy()/(i+1))\n",
    "    print(\"Epoch : \", epoch+1, \" Loss : \", avg_loss.data.numpy()/total_batch)\n",
    "print(\"Training Done !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  97.95\n"
     ]
    }
   ],
   "source": [
    "test_img = mnist_test.test_data.view(-1, 28*28).type(torch.FloatTensor)\n",
    "test_lab = mnist_test.test_labels\n",
    "outputs = model.forward(test_img)\n",
    "pred_val, pred_idx = torch.max(outputs.data, 1)\n",
    "correct = (pred_idx == test_lab).sum()\n",
    "print('Accuracy : ', correct.data.numpy()/len(test_img)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label :  [2]\n",
      "Prediction :  [2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = np.random.randint(0, len(mnist_test)-1)\n",
    "X_single_data = mnist_test.test_data[r:r + 1].view(-1,28*28).float()\n",
    "Y_single_data = mnist_test.test_labels[r:r + 1]\n",
    "\n",
    "single_prediction = model(X_single_data)\n",
    "plt.imshow(X_single_data.data.view(28,28).numpy(), cmap='gray')\n",
    "\n",
    "print('Label : ', Y_single_data.data.view(1).numpy())\n",
    "print('Prediction : ', torch.max(single_prediction.data, 1)[1].numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
